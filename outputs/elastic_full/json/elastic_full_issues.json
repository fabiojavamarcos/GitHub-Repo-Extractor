[["1", "Query DSL: Terms Filter", "Shay Banon", "kimchy", "02/09/10, 08:19:00 PM", "Support terms filter which allows to configure more than one term for a specific field. For example:\n\n```\n{\n    filteredQuery : {\n        query : {\n            term : { \"name.first\" : \"shay\" }\n        },\n        filter : {\n            terms : {\n                \"name.last\" : [\"banon\", \"kimchy\"]\n            }\n        }\n    }\n}\n```", "Support terms filter, closed by bd2b0a632bfc5aabb408e7f47cfaa52a7d1b2b50\n =||= "], ["2", "Discovery: Support local (JVM level) discovery", "Shay Banon", "kimchy", "02/10/10, 10:12:58 PM", "Allow to have a JVM (well, actually class loader) level discovery for simple testing / embedding of a single node (which, potentially exists with other nodes in the same class loader).\n\nEnable it using:\n\n```\ndiscovery:\n    type: local\n```\n\nOr using:\n\n```\nnode:\n    local: true\n```\n\n(which will also enable other modules to be local, such as the transport - once we have that...)", "Discovery: Support local (JVM level) discovery. Closed by b61964a2b8a4f6465928efcb5b1b434dbbb6b1a5.\n =||= "], ["3", "Transport: Support local (JVM level) transport", "Shay Banon", "kimchy", "02/11/10, 05:29:31 PM", "Allow to have a JVM (well, actually class loader) level transport for simple testing / embedding of a single node (which, potentially exists with other nodes in the same class loader).\n\nEnable it using:\n\n```\ntransport:\n    type: local\n```\n\nOr using:\n\n```\nnode:\n    local: true\n```\n\n(which will also enable other modules to be local, such as the discovery)", "Transport: Support local (JVM level) transport. Closed by 847db717c66509a817e1b965226ee1e44c08918d.\n =||= "], ["4", "Any plans to add geospatial search?", "Simon Willison", "simonw", "02/12/10, 01:17:46 PM", "It would be incredibly useful to be able to index documents with latitude/longitude positions and run searches that return results ordered by distance from a specific latitude/longitude point.", "Yes, very much. There is a Lucene spatial module that I need to look at. There are other solutions running around. When I support that, I want that to be very closely integrated in terms that you will have a type: location (or something similar).\n\nNot sure it will make it into 0.5, but its certainly on the short list for 0.6.0.\n =||= Thanks - it's a very exciting project, thanks for releasing it!\n =||= I will close this for now, I will add an issue that says \"Spatial Support\" later on \n =||= "], ["5", "Any plans to support faceting?", "Simon Willison", "simonw", "02/12/10, 01:18:05 PM", "One of the most useful features of Solr is faced searching - is that likely to be added to elasticsearch at any point?", "Can you please send questions to the mailing list? This is not a feature request format, its a question that might lead to a discussion which will end up as a feature request. ES has basic support for facet queries, other types of faces are on the road map.\n =||= Sure, I'll use the mailing list for this kind of thing in the future. Thanks for the replies.\n =||= Sure, no problem. To be honest, I don't know where best to conduct this. I now see that others actually maintain a mini forums in the issues, I am simply used to mailing lists to have discussions, and issue trackers to have discussions about open bugs or features implementations. But, maybe I am wrong, and this is a better place, what do you think?\n =||= Closing for now. Will create issues for each new facet support that I plan.\n =||= "], ["6", "Query DSL: Bool query/filter to be valid JSON", "Shay Banon", "kimchy", "02/12/10, 01:24:25 PM", "Currently, the bool query is not a valid Javassctipt (still valid JSON though...) since indicating two must clauses uses the same field name for a JSON object. The old way should still be supported, but, we should also allow for something like this:\n\nCurrently, the bool query is not a valid Javassctipt (still valid JSON though...) since indicating two must clauses uses the same field name for a JSON object. The old way should still be supported, but, we should also allow for something like this:\n\n```\n{\n    bool : {\n        must : [\n            {\n                queryString : {\n                    defaultField : \"content\",\n                    query : \"test1\"\n                }\n            },\n            {\n                queryString : {\n                    defaultField : \"content\",\n                    query : \"test4\"\n                }\n            }\n        ],\n        mustNot: {\n            queryString : {\n                defaultField : \"content\",\n                query : \"test2\"\n            }\n        },\n        should: {\n            queryString : {\n                defaultField : \"content\",\n                query : \"test3\"\n            }\n        }\n    }\n}\n```", "It's definitely still invalid JSON - the JSON spec on http://www.json.org/ is clear that double quotes are required around string values, including object keys. In practice it's not a huge problem that elasticsearch accepts invalid JSON for the queries though, provided it also accepts valid JSON. The JSON output by elasticsearch uses quotes in the right places and is absolutely fine.\n\nPython's JSON parser is strict by default, and throws the following exception if I feed in the above example:\n\nValueError: Expecting property name: line 2 column 5 (char 6)\n =||= The invalid part I was talking about is the usage of the same field name twice within an object. \n\nRegarding the quotes on field names, you are absolutely correct. ES does accept field names that are either quoted or not, for two reasons:\n1. Less text on the wire / simplifies writing examples :).\n2. Makes direct Javascript usage simpler.\n =||= Actually, non-unique key names are invalid JSON.  See section 2.2 in http://www.ietf.org/rfc/rfc4627.txt?number=4627\n\nSo whenever you have repeatable items, you should provide both:\n    { key: value } \n    { keys: [ value_1, value_n ] }\n =||= or:\n\n```\n{ key: value }  | { key: [ value_1, value_n] }\n```\n =||= They say SHOULD not must :). In any case, I will make sure in the future that the SHOULD, with all its uppercase glory, is maintained :).\n =||= "], ["7", "Discovery/Jgroups: Upgrade to 2.9.0", "Shay Banon", "kimchy", "02/12/10, 04:09:21 PM", "Upgrade to latest JGroups release (2.9.0) from the current (2.8.0)", "Discovery/Jgroups: Upgrade to 2.9.0. Closed by 78eaacccefae44e9cabc44216b26175e830cdcf8.\n =||= "], ["8", "HTTP: Rest API should support receiving HTTP chunks", "Shay Banon", "kimchy", "02/13/10, 09:44:43 PM", "For large messages, certain HTTP clients will chunk the requests. Though it is probably better to disable this if possible on the client side, we should still support chunked HTTP messages.", "HTTP: Rest API should support receiving HTTP. Closed by 5ac51ee93feab6c75fcbe979b9bb338962622c2e.\n =||= "], ["9", "Optimize API: Allow to optimize index/indices", "Shay Banon", "kimchy", "02/14/10, 06:33:37 PM", "Provide the ability to optimize an index or indices down to a provided number of segments.", "Optimize API: Allow to optimize index/indices. Closed by cfafb52bebbd5bb50b4fc74b1aebc121a9e91548.\n =||= is this the correct usage for the options?\n\n```\ncurl -XPOST http://127.0.0.2:9200/_optimize?onlyExpungeDeletes=1&flush=1&refresh=1\n```\n\nta\n\nclint\n =||= Yes, except that the boolean parameters expect true, and not 1. Ohh wait, just pushed support for 1 as well for http parameters to indicate true :)\n =||= By the way, I think I am also going to add support to provide all this parameters in the body of the request as a JSON (instead in the query string), what do you think?\n =||= about you added support for true / 1 - please can you do that for the JSON as well.  For instance:\n\n```\n{ query: {\n        filteredQuery: {\n                query: {............},\n                explain: true      # should accept 1 here as well\n}}\n```\n\nre adding the params to the JSON instead:\n\nyes, that would make sense to me - for a wrapper like ElasticSearch.pm, it makes little difference having the params in one place or the other - it'd probably be easier to just deal with the JSON.\n =||= Added support for 0 to represent false in all places where I parse JSON or http parameters. Will work later on getting support for JSON body as well.\n =||= Hiya\n\nJust had another thought about this:\n\n> By the way, I think I am also going to add support to provide all this \n> parameters in the body of the request as a JSON (instead in the \n> query string), what do you think?\"\n\nOne request that wouldn't work so well is:\n\n```\ncurl -XPUT 'http://127.0.0.2:9200/es_test/type_1/1?opType=create'  -d '\n{\n   \"num\" : 2,\n   \"text\" : \"foo\"\n}\n'\n```\n\nbecause the entire JSON document represents the document being indexed, so slipping opType=create in there wouldn't work\n\nclint\n =||= Yes, I am referring currently only to requests that don't have a body. The one mentioned as the index/delete/create and search operations do not fall into this category. I need to think what a solution (if needed) for them will be.\n =||= "], ["10", "Query http listeners", "Clinton Gormley", "clintongormley", "02/14/10, 07:29:21 PM", "In the same way as you can find out if a node is a data node or not, it'd be good to tell if a node has http enabled or not.\n\nOne of the things I'd like to be able to do, is to query one node about\nthe other http enabled nodes in the cluster (in the same was as you can\nfind out which nodes are data nodes)\n\nIn other words, one of my clients starts up, queries the 'main' node\nabout which listeners are available, then randomly selects one of those\nnodes.\n\nThe idea is to spread the load between the nodes, and also, if a node\ngoes down, then my client already has a list of other nodes that it can\ntry connecting to.\n\nthanks\n\nClint", "Make sense. This will be part of the admin cluster node info API (REST is: http://localhost:9200/_cluster/nodes?pretty=true).\n\nThe json will be:\n\n```\n{\n  \"clusterName\" : \"elasticsearch\",\n  \"nodes\" : {\n    \"mackimchy-45484\" : {\n      \"name\" : \"Commander Kraken\",\n      \"transportAddress\" : \"inet[10.0.0.1/10.0.0.1:9300]\",\n      \"dataNode\" : true,\n      \"httpAddress\" : \"inet[/10.0.0.1:9200]\"\n    },\n    \"mackimchy-13357\" : {\n      \"name\" : \"Ramshot\",\n      \"transportAddress\" : \"inet[/10.0.0.1:9301]\",\n      \"dataNode\" : true,\n      \"httpAddress\" : \"inet[/10.0.0.1:9201]\"\n    }\n  }\n}\n```\n\nNote that it will now wrap the nodes in the \"nodes\" element for simpler usage.\n =||= Query http listeners. Closed by b5f3fc9ae1a68a9114acf1ef2bc9bc4d90ad1bea.\n =||= Ohh, and I added an http parameter to include node settings, just use: http://localhost:9200/_cluster/nodes?settings=true\n =||= "]]